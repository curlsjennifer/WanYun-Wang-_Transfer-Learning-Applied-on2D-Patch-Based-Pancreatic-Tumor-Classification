\chapter{Discussion}
\subsection{The Performance of Each Methods} 
Three-layered fine-tuning method can improve the AUC performance of source model best compared to the other method. Also the calculation cost is small. 
The mixed data method also has relatively good performance, but the calculation cost is huge. 
\subsection{Incremental Learning} 
It had been proofed that the AIFT selection method can select the more valuable patch-based data, but the result on patient-based data is not good enough. Also it doesn't perform better than basic fine-tuning.  

\section{Limitations} 

Since the target data is composed of two dataset: MSD dataset and TCIA dataset, the distribution of two datasets might be different, so the model performance may decrease because of the reason. Also, since the number of data is not large enough, the outliers shows up in cross validation experiments. 

\section{Future Work}
I can try different fine-tuning details of AIFT method, including the  parameters in loss function, number of epochs, or other training details to avoid overfitting or to choose more valuable data. It's possible to increase the performance on target data. 

